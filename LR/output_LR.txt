Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9858044164037855, Test accuracy: 0.832046332046332, F1: 0.8324552810700857
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9810725552050473, Test accuracy: 0.832046332046332, F1: 0.8324552810700857
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9763406940063092, Test accuracy: 0.8146718146718147, F1: 0.8151398990710326
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9787066246056783, Test accuracy: 0.8243243243243243, F1: 0.8247618816934899
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9858044164037855, Test accuracy: 0.8281853281853282, F1: 0.8286137680716028
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9865930599369085, Test accuracy: 0.8359073359073359, F1: 0.8363212545091878
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9810725552050473, Test accuracy: 0.8243243243243243, F1: 0.8247623920732117
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9826498422712934, Test accuracy: 0.832046332046332, F1: 0.8324699899094039
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9818611987381703, Test accuracy: 0.832046332046332, F1: 0.8324552810700857
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9865930599369085, Test accuracy: 0.8359073359073359, F1: 0.8363160433400729
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9858044164037855, Test accuracy: 0.8301158301158301, F1: 0.8305351027021483
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9826498422712934, Test accuracy: 0.8513513513513513, F1: 0.8517132947401906
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9858044164037855, Test accuracy: 0.8359073359073359, F1: 0.836272875033784
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9865930599369085, Test accuracy: 0.8416988416988417, F1: 0.8420778643000866
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9834384858044164, Test accuracy: 0.8243243243243243, F1: 0.8247672885531077
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9834384858044164, Test accuracy: 0.833976833976834, F1: 0.8343961595844666
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9802839116719243, Test accuracy: 0.8436293436293436, F1: 0.843977680914547
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9826498422712934, Test accuracy: 0.8378378378378378, F1: 0.8382448361084989
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9818611987381703, Test accuracy: 0.8243243243243243, F1: 0.8247520756020437
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.9826498422712934, Test accuracy: 0.8127413127413128, F1: 0.8131963823254424
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 15.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} => Train accuracy: 0.5149842271293376, Test accuracy: 0.4498069498069498, F1: 0.27910790760324716
=====================================================
Best Params: {Param(parent='LogisticRegression_fb90fa3cb9ab', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 2, Param(parent='LogisticRegression_fb90fa3cb9ab', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial'): 'auto', Param(parent='LogisticRegression_fb90fa3cb9ab', name='featuresCol', doc='features column name.'): 'features', Param(parent='LogisticRegression_fb90fa3cb9ab', name='fitIntercept', doc='whether to fit an intercept term.'): True, Param(parent='LogisticRegression_fb90fa3cb9ab', name='labelCol', doc='label column name.'): 'fraudulent', Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxBlockSizeInMB', doc='maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0.'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='maxIter', doc='max number of iterations (>= 0).'): 3, Param(parent='LogisticRegression_fb90fa3cb9ab', name='predictionCol', doc='prediction column name.'): 'prediction', Param(parent='LogisticRegression_fb90fa3cb9ab', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability', Param(parent='LogisticRegression_fb90fa3cb9ab', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction', Param(parent='LogisticRegression_fb90fa3cb9ab', name='regParam', doc='regularization parameter (>= 0).'): 0.0, Param(parent='LogisticRegression_fb90fa3cb9ab', name='standardization', doc='whether to standardize the training features before fitting the model.'): True, Param(parent='LogisticRegression_fb90fa3cb9ab', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5, Param(parent='LogisticRegression_fb90fa3cb9ab', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'): 1e-06}
